{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bagging, Boosting , Stacking\n",
    "Source(EN):https://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging:\n",
    "1. parallel ensemble: each model is built independently\n",
    "2. aim to decrease variance, not bias\n",
    "3. suitable for high variance low bias models (complex models)\n",
    "4. an example of a tree based method is random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting: \n",
    "1. sequential ensemble: try to add new models that do well where previous models lack\n",
    "2. aim to decrease bias, not variance\n",
    "3. suitable for low variance high bias models\n",
    "4. an example of a tree based method is gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bagging](Figure/Bagging_vs_Boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Application Example\n",
    "Source: Python Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Stacking\n",
    "训练样本一样，基础模型不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X,y = iris.data[50:,[1,2]],iris.target[50:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(penalty='l2',C=0.001,random_state=0)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1,criterion='entropy',random_state=0)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,p=2,metric='minkowski')\n",
    "pipe1 = Pipeline([['sc',StandardScaler()],['clf',clf1]])\n",
    "#pipe2 = Pipeline([['sc',StandardScaler()],['clf',clf2]])\n",
    "pipe3 = Pipeline([['sc',StandardScaler()],['clf',clf3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_labels = ['LR','DT','KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.92 (+/- 0.20) [LR]\n",
      "ROC AUC: 0.92 (+/- 0.15) [DT]\n",
      "ROC AUC: 0.93 (+/- 0.10) [KNN]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/TobiasChen/miniconda3/envs/csh/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf,label in zip([pipe1,clf2,pipe3],clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\"% (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf = VotingClassifier(estimators=[('LR', pipe1), ('DT', clf2), ('KNN', pipe3)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = cross_val_score(estimator=mv_clf,X=X_train,y=y_train,cv=10,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97 (+/- 0.10) [Voting]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"% (score.mean(), score.std(), 'Voting'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有放回的抽样，基础模型一样，训练样本不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.columns = ['Class label', 'Alcohol',\n",
    "                     'Malic acid', 'Ash',\n",
    "                       'Alcalinity of ash',\n",
    "                       'Magnesium', 'Total phenols',\n",
    "                       'Flavanoids', 'Nonflavanoid phenols',\n",
    "                       'Proanthocyanins',\n",
    "                       'Color intensity', 'Hue',\n",
    "                       'OD280/OD315 of diluted wines',\n",
    "                      'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = df_wine[df_wine['Class label'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_wine['Class label'].values\n",
    "X = df_wine[['Alcohol', 'Hue']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size=0.4,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy',max_depth=None)\n",
    "bag = BaggingClassifier(base_estimator=tree,\n",
    "                        n_estimators=500,\n",
    "                        max_samples = 1.0,\n",
    "                        max_features=1.0,\n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False,\n",
    "                        n_jobs=1,\n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 1.000/0.854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "tree = tree.fit(X_train, y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' % (tree_train, tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging train/test accuracies 1.000/0.896\n"
     ]
    }
   ],
   "source": [
    "bag = bag.fit(X_train, y_train)\n",
    "y_train_pred = bag.predict(X_train)\n",
    "y_test_pred = bag.predict(X_test)\n",
    "bag_train = accuracy_score(y_train, y_train_pred)\n",
    "bag_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Bagging train/test accuracies %.3f/%.3f'% (bag_train, bag_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 0.845/0.854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                               max_depth=1)\n",
    "ada = AdaBoostClassifier(base_estimator=tree,\n",
    "                          n_estimators=500,\n",
    "                          learning_rate=0.1,\n",
    "                          random_state=0)\n",
    "tree = tree.fit(X_train, y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f'% (tree_train, tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost train/test accuracies 1.000/0.875\n"
     ]
    }
   ],
   "source": [
    "ada = ada.fit(X_train, y_train)\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "ada_train = accuracy_score(y_train, y_train_pred)\n",
    "ada_test = accuracy_score(y_test, y_test_pred)\n",
    "print('AdaBoost train/test accuracies %.3f/%.3f'% (ada_train, ada_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
