{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Time Delay Neural Network\n",
    "Source(CN):https://blog.csdn.net/richard2357/article/details/16896837  \n",
    "Source(EN): Phoneme Recognition Using Time-Delay Neural Networks    \n",
    "feed forward neural network  \n",
    "TDNN thus avoids having to determine the beginning and end points of sounds before classifying them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction\n",
    "CNN前驱，初衷是为了解决语音识别中传统方法HMM无法适应语音信号中的动态时域变化，并且该结构参数较少，进行语音识别不需要预先将音标与音频在时间线上进行对齐，实验证明TDNN相比HMM表现更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 TDNN Structure\n",
    "![title](Figure/TDNN.png)\n",
    "\n",
    "共4层:\n",
    "Input Layer: 16个特征，time delay 2, 16*3*8 = 384\n",
    "HL1: 8个单元，time delay 4, 8*5*3 = 120\n",
    "HL2: 3个单元，time delay 8, 3*9*3 = 81\n",
    "共585个参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Advantage\n",
    "1. 网络是多层的，每层对特征有较强的抽象能力。\n",
    "2. 有能力表达语音特征在时间上的关系。\n",
    "3. 具有时间不变性。\n",
    "4. 学习过程中不要求对所学的标记进行精确的时间定为。\n",
    "5. 通过共享权值，方便学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift invariant classification\n",
    "Shift-invariant classification means that the classifier does not require explicit segmentation prior to classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TCN(Temporal convolutional network)\n",
    "Source: An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling  \n",
    "Source(EN)https://www.datasciencecentral.com/profiles/blogs/temporal-convolutional-nets-tcns-take-over-from-rnns-for-nlp-pred  \n",
    "Source(CN): http://nooverfit.com/wp/%E6%97%B6%E9%97%B4%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9Ctcn-%E6%80%BB%E7%BB%93%EF%BC%9A%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B%E4%B8%8D%E5%86%8D%E6%98%AF%E9%80%92%E5%BD%92%E7%BD%91%E7%BB%9Crnn/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TCN Structure\n",
    "![TCN](Figure/TCN.png)\n",
    "![Residual_Block](Figure/Residual_Block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCN只是一维卷积变形之后在时序问题上变得适用  \n",
    "时序预测要求对时刻t 的预测yt只能通过t时刻之前的输入x1到xt-1来判别（像隐马尔科夫链）。这在CNN里面就叫做因果卷积（causalconvolutions）。本质上，David 9认为就是通过限制卷积窗口滑动做到的。  \n",
    "TCN还为了提高准确率，还加入了残差卷积的跳层连接，以及1×1的卷积操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source(CN): https://www.zhihu.com/question/278551486/answer/415692765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Background Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 感受野(receptive field)\n",
    "感受野是卷积核在图像上看到的大小，例如3×3卷积核的感受野大小为9。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 卷积 (Convolution)\n",
    "Source(CN):https://www.zhihu.com/question/22298352  \n",
    "Source(CN): https://www.jiqizhixin.com/articles/2018-04-12-3  \n",
    "一般来说，卷积运算主要通过稀疏权重、参数共享和平移等变性等特性加强了机器学习系统\n",
    "1. 稀疏权重:即卷积核大小会远小于输入图像的大小，这允许卷积网络存储更少的参数和使用更少的计算而实现高效的性能  \n",
    "2. 参数共享:我们假设数据拥有局部结构，那么只需要在小范围神经元中使用不同的参数，而大范围内的神经元可共享参数  \n",
    "3. 平移不变性:建立在参数共享的基础上，它可以直观理解为若移动输入中对象，那么输出中的表示也会移动同样的量  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 扩张卷积(dilated convolution)\n",
    "扩张卷积与普通的卷积相比，除了卷积核的大小以外，还有一个扩张率(dilation rate)参数，主要用来表示扩张的大小。扩张卷积与普通卷积的相同点在于，卷积核的大小是一样的，神经网络中的参数数量不变。两者区别区别在于扩张卷积具有更大的感受野。  \n",
    "扩张卷积的好处是不做pooling损失信息的情况下，加大了感受野，让每个卷积输出都包含较大范围的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 因果卷积(causalconvolutions)\n",
    "Artical: WaveNet（van den Oord et al., 2016）  \n",
    "因果卷积的理解可以认为是：不管是自然语言处理领域中的预测还是时序预测，都要求对时刻t 的预测yt只能通过t时刻之前的输入x1到xt-1来判别。这种思想有点类似于马尔科夫链。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5全卷积网络(Fully Convolutional Networks)\n",
    "Artical: Fully Convolutional Networks for Semantic Segmentation\n",
    "它将传统卷积神经网络最后几个全连接层替换为卷积层,它能实现密集型的预测，即在二维卷积下对图像实现像素级的分类，在一维卷积下对序列实现元素级的预测\n",
    "![FCN](Figure/Fully_Connection_Layer.jpg)  \n",
    "通过使用一维全卷积网络，TCN 可以产生和输入序列等长的输出序列，且每一个隐藏层通过使用 Padding 可以保持和输出层等长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 长期依赖\n",
    "TCN 还强调利用残差模块和空洞卷积来构建长期依赖关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 高速公路网络（Highway Networks）\n",
    "在高速公路网络中，传入后一层的信息不仅是当前层的计算结果，同时还包含了前面层级的计算结果。高速公路网络会使用门控机制控制每一层向后传递的信息\n",
    "![Highway](Figure/Highway.jpg)\n",
    "其中 H(x, W_H) 表示当前层传统卷积运算的结果，而非线性函数 T(x, W_T) 表示转换门，它控制了当前层的卷积运算结果对当前层输出的贡献大小。C(x,W_C) 表示携带门，它控制了当前层的输入信息最终不经过计算直接传到输出端的大小。高速公路网络一般采用 1-T(x, W_T) 代替 C(x,W_C) 而减少门控的数量，且门控通过 Sigmoid 函数实现。  \n",
    "如果我们令上式的 T 和 C 都等于 1，那么它就代表了一个残差模块，即 y = H(x, W_H) + x。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 残差卷积\n",
    "连接微软的残差网络 ResNet 就是经典的跳层连接（skip-connection），如下图所示\n",
    "![title](Figure/skip_connection.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 TCN Advantage\n",
    "1. Speed is important. Faster networks shorten the feedback cycle.  The massive parallelism available with TCNs shortens both training and evaluation cycles.\n",
    "2. TCNs offer more flexibility in changing its receptive field size, principally by stacking more convolutional layers, using larger dilation factors, or increasing filter size. This offers better control of the model’s memory size.\n",
    "3. TCNs have a backpropagation path different from the temporal direction of the sequence. This avoids the problem of exploding or vanishing gradients which are a major issue with RNNs.\n",
    "4. Lower memory requirement for training, especially in the case of long input sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 TCN CODE\n",
    "https://github.com/locuslab/TCN/tree/master/TCN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
